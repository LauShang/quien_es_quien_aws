{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "italic-invalid",
   "metadata": {},
   "source": [
    "# Spark Machine Learning using linear regression\n",
    "\n",
    "\n",
    "#### Topics covered in this example\n",
    "* `VectorAssembler`, `LinearRegression` and `RegressionEvaluator` from `pyspark.ml`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-dominant",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Prerequisites\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE :</b> In order to execute this notebook successfully as is, please ensure the following prerequisites are completed.</div>\n",
    "\n",
    "* The EMR cluster attached to this notebook should have the `Spark` application installed.\n",
    "* This example uses a public dataset, hence the EMR cluster attached to this notebook must have internet connectivity.\n",
    "* This notebook uses the `PySpark` kernel.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-violence",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this example we use pyspark to predict the total cost of a trip using <a href=\"https://registry.opendata.aws/nyc-tlc-trip-records-pds/\" target=\"_blank\">New York City Taxi and Limousine Commission (TLC) Trip Record Data</a> from <a href=\"https://registry.opendata.aws/\" target=\"_blank\">Registry of Open Data on AWS</a>.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-enough",
   "metadata": {},
   "source": [
    "## Example\n",
    "Load the data set for trips into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "human-probe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\") \\\n",
    ".load(\"s3://itam-analytics-MINOMBRE/taxi/yellow_tripdata_2022-*.parquet\", \n",
    "      inferSchema = True, \n",
    "      header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-panama",
   "metadata": {},
   "source": [
    "Mark the dataFrame for caching in memory and display the schema to check the data-types using the `printSchema` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinct-dollar",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n",
      "(39656098, 19)"
     ]
    }
   ],
   "source": [
    "# Mark the dataFrame for caching in memory\n",
    "df.cache()\n",
    "\n",
    "# Print the scehma\n",
    "df.printSchema()\n",
    "\n",
    "# Get the dimensions of the data\n",
    "df.count() , len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "descending-messaging",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|      total_amount|        tip_amount|\n",
      "+-------+------------------+------------------+\n",
      "|  count|          39656098|          39656098|\n",
      "|   mean|21.671268443305777| 7.234908207598432|\n",
      "| stddev| 96.37360220544356|22328.083995040284|\n",
      "|    min|           -2567.8|            -410.0|\n",
      "|    max|         401095.62|    1.3339136353E8|\n",
      "+-------+------------------+------------------+\n",
      "\n",
      "+--------+--------+\n",
      "|VendorID|   count|\n",
      "+--------+--------+\n",
      "|       5|     143|\n",
      "|       6|   59601|\n",
      "|       1|11271061|\n",
      "|       2|28325293|\n",
      "+--------+--------+"
     ]
    }
   ],
   "source": [
    "# Get the summary of the columns\n",
    "df.select(\"total_amount\", \"tip_amount\")\\\n",
    ".describe()\\\n",
    ".show()\n",
    "\n",
    "# Value counts of VendorID column\n",
    "df.groupBy(\"VendorID\")\\\n",
    ".count()\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-maintenance",
   "metadata": {},
   "source": [
    "### Use <a href=\"https://spark.apache.org/docs/2.4.7/ml-features#vectorassembler\" target=\"_blank\">VectorAssembler</a> to transform input columns into vectors\n",
    "<a href=\"https://spark.apache.org/docs/2.3.1/api/python/pyspark.ml.html\" target=\"_blank\">pyspark.ml</a> provides dataFrame-based machine learning APIs to let users quickly assemble and configure practical machine learning pipelines.    \n",
    "A `VectorAssembler` combines a given list of columns into a single vector column. In the below cell we combine the columns to a single vector cloumn `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "magnetic-anaheim",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|total_amount|\n",
      "+--------------------+------------+\n",
      "|[2.4,90.0,209.0,1...|        13.8|\n",
      "|[2.2,148.0,234.0,...|        14.3|\n",
      "|[19.78,132.0,249....|       67.61|\n",
      "+--------------------+------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Specify the input and output columns of the vector assembler\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols = [\n",
    "        \"trip_distance\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"fare_amount\",\n",
    "        \"mta_tax\",\n",
    "        \"tip_amount\", \n",
    "        \"tolls_amount\",\n",
    "        \"improvement_surcharge\", \n",
    "        \"congestion_surcharge\"\n",
    "    ], \n",
    "    outputCol = \"features\")\n",
    "\n",
    "# Transform the data\n",
    "v_df = vectorAssembler.setHandleInvalid(\"skip\").transform(df)\n",
    "\n",
    "# View the transformed data\n",
    "v_df = v_df.select([\"features\", \"total_amount\"])\n",
    "v_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-surge",
   "metadata": {},
   "source": [
    "Divide input dataset into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "monthly-ranch",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splits = v_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-terror",
   "metadata": {},
   "source": [
    "### Train the model using <a href=\"https://spark.apache.org/docs/2.4.7/ml-classification-regression.html#linear-regression\" target=\"_blank\">LinearRegression</a> against training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "golden-industry",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.9975537807494054,1.1988509011648747,0.9870092379839718,0.9841238812269312,0.6679739296547181,0.5506685726630876]\n",
      "Intercept: 1.5774462355534828"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = \"features\", \\\n",
    "                      labelCol = \"total_amount\", \\\n",
    "                      maxIter = 100, \\\n",
    "                      regParam = 0.3, \\\n",
    "                      elasticNetParam = 0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-buddy",
   "metadata": {},
   "source": [
    "Report the trained model performance on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "waiting-healthcare",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.838512\n",
      "R squred (R2): 0.999943"
     ]
    }
   ],
   "source": [
    "training_summary = lr_model.summary\n",
    "print(\"RMSE: %f\" % training_summary.rootMeanSquaredError)\n",
    "print(\"R squred (R2): %f\" % training_summary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-serve",
   "metadata": {},
   "source": [
    "Predict the result using test set and report accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arabic-corpus",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+------------------+------------------+\n",
      "|        prediction|total_amount|              diff|             diff%|\n",
      "+------------------+------------+------------------+------------------+\n",
      "| 66.41844198426483|        65.0| 1.418441984264831|2.1822184373305094|\n",
      "| 66.41844198426483|        65.0| 1.418441984264831|2.1822184373305094|\n",
      "| 76.39397979175888|        75.0|1.3939797917588805| 1.858639722345174|\n",
      "| 69.41110332651304|        68.0| 1.411103326513043| 2.075151950754475|\n",
      "|20.331457313642307|        18.8|1.5314573136423064| 8.146049540650566|\n",
      "|14.545645385295753|        13.0| 1.545645385295753|11.889579886890408|\n",
      "| 26.51629075428862|        25.0|1.5162907542886188| 6.065163017154475|\n",
      "| 70.00963559496269|        68.6| 1.409635594962694| 2.054862383327542|\n",
      "|  81.3817486955059|        80.0|1.3817486955059053|1.7271858693823816|\n",
      "| 83.37685625700472|        82.0| 1.376856257004718| 1.679092996347217|\n",
      "| 71.40621088801186|        70.0|1.4062108880118558|2.0088726971597937|\n",
      "| 54.44779661527197|        53.0|1.4477966152719688| 2.731691726928243|\n",
      "| 69.41110332651304|        68.0| 1.411103326513043| 2.075151950754475|\n",
      "| 63.42578064201661|        62.0| 1.425780642016612| 2.299646196800987|\n",
      "| 63.42578064201661|        62.3|1.1257806420166148|1.8070315281165565|\n",
      "|13.548091604546347|        12.0|1.5480916045463466|12.900763371219556|\n",
      "|20.530968069792188|        19.0|1.5309680697921877| 8.057726683116776|\n",
      "| 74.94752680967224|       73.55| 1.397526809672243| 1.900104431913315|\n",
      "| 30.50650587728624|        29.0|1.5065058772862407| 5.194847852711175|\n",
      "|28.511398315787428|        27.0| 1.511398315787428|5.5977715399534365|\n",
      "+------------------+------------+------------------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "predictions.filter(predictions.total_amount > 10.0)\\\n",
    ".select(\"prediction\", \"total_amount\")\\\n",
    ".withColumn(\"diff\", col(\"prediction\") - col(\"total_amount\"))\\\n",
    ".withColumn(\"diff%\", (col(\"diff\") / col(\"total_amount\")) * 100)\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-kazakhstan",
   "metadata": {},
   "source": [
    "### Report performance on the test set using <a href=\"https://spark.apache.org/docs/2.4.7/api/java/org/apache/spark/ml/evaluation/RegressionEvaluator.html\" target=\"_blank\">RegressionEvaluator</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thirty-beaver",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.999811"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol = \"prediction\", \\\n",
    "                                   labelCol = \"total_amount\", \\\n",
    "                                   metricName = \"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8ecab-a88c-4840-9550-b3a99c177226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
